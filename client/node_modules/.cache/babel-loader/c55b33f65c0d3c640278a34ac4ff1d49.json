{"ast":null,"code":"var _createForOfIteratorHelper = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createForOfIteratorHelper\");\n\nvar _regeneratorRuntime = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar _inherits = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\n\nvar _createSuper = require(\"/Users/samehrlich/Desktop/final-app/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createSuper\");\n\nvar _require = require(\"./util/promise-transform-stream\"),\n    PromiseTransformStream = _require.PromiseTransformStream;\n\nvar _require2 = require(\"stream\"),\n    Readable = _require2.Readable,\n    Writable = _require2.Writable,\n    Transform = _require2.Transform;\n\nvar scramjet = require(\".\");\n\nvar _require3 = require(\"./util/utils\"),\n    AsyncGeneratorFunction = _require3.AsyncGeneratorFunction,\n    GeneratorFunction = _require3.GeneratorFunction,\n    resolveCalleeBlackboxed = _require3.resolveCalleeBlackboxed,\n    pipeIfTarget = _require3.pipeIfTarget;\n/**\n * DataStream is the primary stream type for Scramjet. When you parse your\n * stream, just pipe it you can then perform calculations on the data objects\n * streamed through your flow.\n *\n * Use as:\n *\n * ```javascript\n * const { DataStream } = require('scramjet');\n *\n * await (DataStream.from(aStream) // create a DataStream\n *     .map(findInFiles)           // read some data asynchronously\n *     .map(sendToAPI)             // send the data somewhere\n *     .run());                    // wait until end\n * ```\n * @memberof module:scramjet.\n * @alias DataStream\n * @borrows module:scramjet.DataStream#bufferify as module:scramjet.DataStream#toBufferStream\n * @borrows module:scramjet.DataStream#stringify as module:scramjet.DataStream#toStringStream\n * @extends import(\"stream\").PassThrough\n */\n\n\nvar DataStream = /*#__PURE__*/function (_PromiseTransformStre) {\n  \"use strict\";\n\n  _inherits(DataStream, _PromiseTransformStre);\n\n  var _super = _createSuper(DataStream);\n\n  /**\n   * Create the DataStream.\n   *\n   * @param {DataStreamOptions} [opts={}] Stream options passed to superclass\n   *\n   * @test test/methods/data-stream-constructor.js\n   */\n  function DataStream(opts) {\n    _classCallCheck(this, DataStream);\n\n    return _super.call(this, Object.assign({\n      objectMode: true,\n      writableObjectMode: true,\n      readableObjectMode: true\n    }, opts));\n  }\n  /**\n   * Returns a DataStream from pretty much anything sensibly possible.\n   *\n   * Depending on type:\n   * * `self` will return self immediately\n   * * `Readable` stream will get piped to the current stream with errors forwarded\n   * * `Array` will get iterated and all items will be pushed to the returned stream.\n   *   The stream will also be ended in such case.\n   * * `GeneratorFunction` will get executed to return the iterator which will be used as source for items\n   * * `AsyncGeneratorFunction` will also work as above (including generators) in node v10.\n   * * `Iterable`s iterator will be used as a source for streams\n   *\n   * You can also pass a `Function` or `AsyncFunction` that will be executed and it's outcome will be\n   * passed again to `from` and piped to the initially returned stream. Any additional arguments will be\n   * passed as arguments to the function.\n   *\n   * If a `String` is passed, scramjet will attempt to resolve it as a module and use the outcome\n   * as an argument to `from` as in the Function case described above. For more information see {@link modules.md}\n   *\n   * A simple example from a generator:\n   *\n   * ```javascript\n   * DataStream\n   *   .from(function* () {\n   *      while(x < 100) yield {x: x++};\n   *   })\n   *   .each(console.log)\n   *   // {x: 0}\n   *   // {x: 1}\n   *   // ...\n   *   // {x: 99}\n   * ```\n   *\n   * @param {Array|Iterable<any>|AsyncGeneratorFunction|GeneratorFunction|AsyncFunction|Promise<any>|Function|string|Readable} input argument to be turned into new stream\n   * @param {DataStreamOptions|Writable} [options={}] options for creation of a new stream or the target stream\n   * @param {any[]} ...args additional arguments for the stream - will be passed to the function or generator\n   * @return {DataStream}\n   */\n\n\n  _createClass(DataStream, [{\n    key: \"map\",\n    value:\n    /**\n     * @callback MapCallback\n     * @memberof module:scramjet~\n     * @param {any} chunk the chunk to be mapped\n     * @returns {Promise<any>|any}  the mapped object\n     */\n\n    /**\n     * Transforms stream objects into new ones, just like Array.prototype.map\n     * does.\n     *\n     * Map takes an argument which is the Function function operating on every element\n     * of the stream. If the function returns a Promise or is an AsyncFunction then the\n     * stream will await for the outcome of the operation before pushing the data forwards.\n     *\n     * A simple example that turns stream of urls into stream of responses\n     *\n     * ```javascript\n     * stream.map(async url => fetch(url));\n     * ```\n     *\n     * Multiple subsequent map operations (as well as filter, do, each and other simple ops)\n     * will be merged together into a single operation to improve performance. Such behaviour\n     * can be suppressed by chaining `.tap()` after `.map()`.\n     *\n     * @param {MapCallback} func The function that creates the new object\n     * @param {function(new:DataStream)} [ClassType=this.constructor] The class to be mapped to.\n     * @chainable\n     *\n     * @test test/methods/data-stream-map.js\n     */\n    function map(func) {\n      var ClassType = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this.constructor;\n      return this.pipe(new ClassType({\n        promiseTransform: func,\n        referrer: this\n      }));\n    }\n    /**\n     * @callback FilterCallback\n     * @memberof module:scramjet~\n     * @param {any} chunk the chunk to be filtered or not\n     * @returns {Promise<Boolean>|Boolean} information if the object should remain in the filtered stream.\n     */\n\n    /**\n     * Filters object based on the function outcome, just like Array.prototype.filter.\n     *\n     * Filter takes a Function argument which should be a Function or an AsyncFunction that\n     * will be called on each stream item. If the outcome of the operation is `falsy` (`0`, `''`,\n     * `false`, `null` or `undefined`) the item will be filtered from subsequent operations\n     * and will not be pushed to the output of the stream. Otherwise the item will not be affected.\n     *\n     * A simple example that filters out non-2xx responses from a stream\n     *\n     * ```javascript\n     * stream.filter(({statusCode}) => !(statusCode >= 200 && statusCode < 300));\n     * ```\n     *\n     * @chainable\n     * @param  {FilterCallback} func The function that filters the object\n     *\n     * @test test/methods/data-stream-filter.js\n     */\n\n  }, {\n    key: \"filter\",\n    value: function filter(func) {\n      return this.pipe(this._selfInstance({\n        promiseTransform: func,\n        afterTransform: function afterTransform(chunk, ret) {\n          return ret ? chunk : Promise.reject(DataStream.filter);\n        },\n        referrer: this\n      }));\n    }\n    /**\n     * @callback ReduceCallback\n     * @memberof module:scramjet~\n     * @param {any} accumulator the accumulator - the object initially passed or returned by the previous reduce operation\n     * @param {object} chunk the stream chunk.\n     * @return {Promise<any>|any}  accumulator for the next pass\n     */\n\n    /**\n     * Reduces the stream into a given accumulator\n     *\n     * Works similarly to Array.prototype.reduce, so whatever you return in the\n     * former operation will be the first operand to the latter. The result is a\n     * promise that's resolved with the return value of the last transform executed.\n     *\n     * A simple example that sums values from a stream\n     *\n     * ```javascript\n     * stream.reduce((accumulator, {value}) => accumulator + value);\n     * ```\n     *\n     * This method is serial - meaning that any processing on an entry will\n     * occur only after the previous entry is fully processed. This does mean\n     * it's much slower than parallel functions.\n     *\n     * @async\n     * @param {ReduceCallback} func The into object will be passed as the  first argument, the data object from the stream as the second.\n     * @param {object} into Any object passed initially to the transform function\n     *\n     * @test test/methods/data-stream-reduce.js\n     */\n\n  }, {\n    key: \"reduce\",\n    value: function reduce(func, into) {\n      var last = Promise.resolve(into);\n      return this.tap().pipe(new PromiseTransformStream({\n        promiseTransform: function promiseTransform(chunk) {\n          return last = last.then(function (acc) {\n            return func(acc, chunk);\n          });\n        },\n        referrer: this,\n        initial: into\n      })).resume().whenFinished().then(function () {\n        return last;\n      });\n    }\n    /**\n     * @callback DoCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {object} chunk source stream chunk\n     * @returns {Promise<any>|any} the outcome is discarded\n     */\n\n    /**\n     * Perform an asynchronous operation without changing or resuming the stream.\n     *\n     * In essence the stream will use the call to keep the backpressure, but the resolving value\n     * has no impact on the streamed data (except for possible mutation of the chunk itself)\n     *\n     * @chainable\n     * @param {DoCallback} func the async function\n     */\n\n  }, {\n    key: \"do\",\n    value: function _do(func) {\n      return this.map( /*#__PURE__*/function () {\n        var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(chunk) {\n          return _regeneratorRuntime.wrap(function _callee$(_context) {\n            while (1) {\n              switch (_context.prev = _context.next) {\n                case 0:\n                  _context.next = 2;\n                  return func(chunk);\n\n                case 2:\n                  return _context.abrupt(\"return\", chunk);\n\n                case 3:\n                case \"end\":\n                  return _context.stop();\n              }\n            }\n          }, _callee);\n        }));\n\n        return function (_x) {\n          return _ref.apply(this, arguments);\n        };\n      }());\n    }\n    /**\n     * Processes a number of functions in parallel, returns a stream of arrays of results.\n     *\n     * This method is to allow running multiple asynchronous operations and receive all the\n     * results at one, just like Promise.all behaves.\n     *\n     * Keep in mind that if one of your methods rejects, this behaves just like Promise.all\n     * you won't be able to receive partial results.\n     *\n     * @chainable\n     * @param {Function[]} functions list of async functions to run\n     *\n     * @test test/methods/data-stream-all.js\n     */\n\n  }, {\n    key: \"all\",\n    value: function all(functions) {\n      return this.map(function (chunk) {\n        var chunkPromise = Promise.resolve(chunk);\n        return Promise.all(functions.map(function (func) {\n          return chunkPromise.then(func);\n        }));\n      });\n    }\n    /**\n     * Processes a number of functions in parallel, returns the first resolved.\n     *\n     * This method is to allow running multiple asynchronous operations awaiting just the\n     * result of the quickest to execute, just like Promise.race behaves.\n     *\n     * Keep in mind that if one of your methods it will only raise an error if that was\n     * the first method to reject.\n     *\n     * @chainable\n     * @param {Function[]} functions list of async functions to run\n     *\n     * @test test/methods/data-stream-race.js\n     */\n\n  }, {\n    key: \"race\",\n    value: function race(functions) {\n      return this.map(function (chunk) {\n        var chunkPromise = Promise.resolve(chunk);\n        return Promise.race(functions.map(function (func) {\n          return chunkPromise.then(func);\n        }));\n      });\n    }\n    /**\n     * Allows processing items without keeping order\n     *\n     * This method useful if you are not concerned about the order in which the\n     * chunks are being pushed out of the operation. The `maxParallel` option is\n     * still used for keeping a number of simultaneous number of parallel operations\n     * that are currently happening.\n     *\n     * @param {MapCallback} func the async function that will be unordered\n     */\n\n  }, {\n    key: \"unorder\",\n    value: function unorder(func) {\n      var _this = this;\n\n      var waiting = [];\n      var processing = Array(this._options.maxParallel).fill(null);\n\n      var out = this._selfInstance({\n        referrer: this\n      });\n\n      this.each( /*#__PURE__*/function () {\n        var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(chunk) {\n          var slot;\n          return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n            while (1) {\n              switch (_context2.prev = _context2.next) {\n                case 0:\n                  // we're using this race condition on purpose\n\n                  /* eslint-disable require-atomic-updates */\n                  slot = processing.findIndex(function (x) {\n                    return x === null;\n                  });\n                  if (slot < 0 && processing.length < _this._options.maxParallel) slot = processing.length;\n\n                  if (!(slot < 0)) {\n                    _context2.next = 6;\n                    break;\n                  }\n\n                  _context2.next = 5;\n                  return new Promise(function (res) {\n                    return waiting.push(res);\n                  });\n\n                case 5:\n                  slot = _context2.sent;\n\n                case 6:\n                  processing[slot] = Promise.resolve(chunk).then(func).then(function (result) {\n                    return out.whenWrote(result);\n                  }).then(function () {\n                    var next = waiting.shift();\n                    if (next) next(slot);else processing[slot] = null;\n                  });\n                  /* eslint-enable require-atomic-updates */\n\n                case 7:\n                case \"end\":\n                  return _context2.stop();\n              }\n            }\n          }, _callee2);\n        }));\n\n        return function (_x2) {\n          return _ref2.apply(this, arguments);\n        };\n      }()).run().then(function () {\n        return Promise.all(processing);\n      }).then(function () {\n        return out.end();\n      });\n      return out;\n    }\n    /**\n     * @callback IntoCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {*} into stream passed to the into method\n     * @param {any} chunk source stream chunk\n     * @return {Promise<any>|any} resolution for the old stream (for flow control only)\n     */\n\n    /**\n     * Allows own implementation of stream chaining.\n     *\n     * The async Function is called on every chunk and should implement writes in it's own way. The\n     * resolution will be awaited for flow control. The passed `into` argument is passed as the first\n     * argument to every call.\n     *\n     * It returns the DataStream passed as the second argument.\n     *\n     * @chainable\n     * @param  {IntoCallback} func the method that processes incoming chunks\n     * @param  {DataStream} into the DataStream derived class\n     *\n     * @test test/methods/data-stream-into.js\n     */\n\n  }, {\n    key: \"into\",\n    value: function into(func, _into) {\n      if (!(_into instanceof DataStream)) throw new Error(\"Stream must be passed!\");\n      if (!_into._options.referrer) _into.setOptions({\n        referrer: this\n      });\n      this.tap().catch(function (e) {\n        return _into.raise(e);\n      }).pipe(new this.constructor({\n        promiseTransform: function () {\n          var _promiseTransform = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(chunk) {\n            return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n              while (1) {\n                switch (_context3.prev = _context3.next) {\n                  case 0:\n                    _context3.prev = 0;\n                    _context3.next = 3;\n                    return func(_into, chunk);\n\n                  case 3:\n                    _context3.next = 8;\n                    break;\n\n                  case 5:\n                    _context3.prev = 5;\n                    _context3.t0 = _context3[\"catch\"](0);\n\n                    _into.raise(_context3.t0);\n\n                  case 8:\n                  case \"end\":\n                    return _context3.stop();\n                }\n              }\n            }, _callee3, null, [[0, 5]]);\n          }));\n\n          function promiseTransform(_x3) {\n            return _promiseTransform.apply(this, arguments);\n          }\n\n          return promiseTransform;\n        }(),\n        referrer: this\n      })).on(\"end\", function () {\n        return _into.end();\n      }).resume();\n      return _into;\n    }\n    /**\n     * @callback UseCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {DataStream} stream\n     * @param  {any[]} ...parameters\n     * @returns {DataStream}\n     */\n\n    /**\n     * Calls the passed method in place with the stream as first argument, returns result.\n     *\n     * The main intention of this method is to run scramjet modules - transforms that allow complex transforms of\n     * streams. These modules can also be run with [scramjet-cli](https://github.com/signicode/scramjet-cli) directly\n     * from the command line.\n     *\n     * @chainable\n     * @param {AsyncGeneratorFunction|GeneratorFunction|UseCallback|string|Readable} func if passed, the function will be called on self to add an option to inspect the stream in place, while not breaking the transform chain. Alternatively this can be a relative path to a scramjet-module. Lastly it can be a Transform stream.\n     * @param {any[]} ...parameters any additional parameters top be passed to the module\n     * @test test/methods/data-stream-use.js\n     */\n\n  }, {\n    key: \"use\",\n    value: function use(func) {\n      var _this2 = this;\n\n      if (typeof func == \"string\") {\n        func = require(func.startsWith(\".\") ? resolveCalleeBlackboxed(func) : func);\n      }\n\n      if (func instanceof Transform || typeof func.readable === \"boolean\" && func.readable && typeof func.writable === \"boolean\" && func.writable && typeof func.pipe === \"function\" && typeof func.on === \"function\") {\n        return this.constructor.from(this.pipe(func));\n      }\n\n      for (var _len = arguments.length, parameters = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        parameters[_key - 1] = arguments[_key];\n      }\n\n      if (func instanceof GeneratorFunction || func instanceof AsyncGeneratorFunction) {\n        var _this$constructor;\n\n        return (_this$constructor = this.constructor).from.apply(_this$constructor, [func, {}, this].concat(parameters));\n      }\n\n      if (typeof func === \"function\") {\n        var result = func.apply(void 0, [this].concat(parameters));\n\n        if (result instanceof Promise) {\n          var out = new this.constructor();\n          result.then(function (res) {\n            return _this2.constructor.from(res).pipe(out);\n          }).catch(function (e) {\n            return out.raise(e);\n          });\n          return out;\n        } else {\n          return result;\n        }\n      }\n\n      throw new Error(\"Unknown argument type.\");\n    }\n    /**\n     * Consumes all stream items doing nothing. Resolves when the stream is ended.\n     *\n     * This is very convienient if you're looking to use up the stream in operations that work on each entry like `map`. This uncorks the stream\n     * and allows all preceding operations to be run at any speed.\n     *\n     * All the data of the current stream will be discarded.\n     *\n     * The function returns a promise that is resolved when the stream ends.\n     *\n     * @async\n     */\n\n  }, {\n    key: \"run\",\n    value: function () {\n      var _run = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4() {\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                return _context4.abrupt(\"return\", this.tap().pipe(new DataStream()).on(\"data\", function () {\n                  return 0;\n                }).whenEnd());\n\n              case 1:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function run() {\n        return _run.apply(this, arguments);\n      }\n\n      return run;\n    }()\n    /**\n     * Creates a pipeline of streams and returns a scramjet stream.\n     *\n     * This is similar to node.js stream pipeline method, but also takes scramjet modules\n     * as possibilities in an array of transforms. It may be used to run a series of non-scramjet\n     * transform streams.\n     *\n     * The first argument is anything streamable and will be sanitized by {@link DataStream..from}.\n     *\n     * Each following argument will be understood as a transform and can be any of:\n     * * AsyncFunction or Function - will be executed by {@link DataStream..use}\n     * * A transform stream that will be piped to the preceding stream\n     *\n     * @param {Array|Iterable<any>|AsyncGeneratorFunction|GeneratorFunction|AsyncFunction|Function|string|Readable} readable the initial readable argument that is streamable by scramjet.from\n     * @param {Array<AsyncFunction|Function|Transform>} ...transforms Transform functions (as in {@link DataStream..use}) or Transform streams (any number of these as consecutive arguments)\n     *\n     * @returns {DataStream} a new DataStream instance of the resulting pipeline\n     */\n\n  }, {\n    key: \"copy\",\n    value:\n    /**\n     * Stops merging transform Functions at the current place in the command chain.\n     *\n     * @name tap\n     * @chainable\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @test test/methods/data-stream-tap.js\n     */\n\n    /**\n     * Reads a chunk from the stream and resolves the promise when read.\n     *\n     * @async\n     * @name whenRead\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Writes a chunk to the stream and returns a Promise resolved when more chunks can be written.\n     *\n     * @async\n     * @name whenWrote\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {*} chunk a chunk to write\n     * @param {any[]} ...more more chunks to write\n     */\n\n    /**\n     * Resolves when stream ends - rejects on uncaught error\n     *\n     * @async\n     * @name whenEnd\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Returns a promise that resolves when the stream is drained\n     *\n     * @async\n     * @name whenDrained\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Returns a promise that resolves (!) when the stream is errors\n     *\n     * @async\n     * @name whenError\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Allows resetting stream options.\n     *\n     * It's much easier to use this in chain than constructing new stream:\n     *\n     * ```javascript\n     *     stream.map(myMapper).filter(myFilter).setOptions({maxParallel: 2})\n     * ```\n     *\n     * @meta.conditions keep-order,chain\n     *\n     * @memberof module:scramjet.DataStream#\n     * @name setOptions\n     * @method\n     * @param {DataStreamOptions} options\n     * @chainable\n     */\n\n    /**\n     * Returns a copy of the stream\n     *\n     * Creates a new stream and pushes all the data from the current one to the new one.\n     * This can be called serveral times.\n     *\n     * @chainable\n     * @param {TeeCallback|Writable} func The duplicate stream will be passed as first argument.\n     */\n    function copy() {\n      return this.tap().pipe(this._selfInstance());\n    }\n    /**\n     * Duplicate the stream\n     *\n     * Creates a duplicate stream instance and passes it to the Function.\n     *\n     * @chainable\n     * @param {TeeCallback|Writable} func The duplicate stream will be passed as first argument.\n     *\n     * @test test/methods/data-stream-tee.js\n     */\n\n  }, {\n    key: \"tee\",\n    value: function tee(func) {\n      if (func instanceof Writable) return this.tap().pipe(func), this;\n      func(this.pipe(this._selfInstance()));\n      return this.tap();\n    }\n    /**\n     * @callback TeeCallback\n     * @memberof module:scramjet~\n     * @param {DataStream} teed The teed stream\n     */\n\n    /**\n     * Performs an operation on every chunk, without changing the stream\n     *\n     * This is a shorthand for ```stream.on(\"data\", func)``` but with flow control.\n     * Warning: this resumes the stream!\n     *\n     * @chainable\n     * @param  {MapCallback} func a Function called for each chunk.\n     */\n\n  }, {\n    key: \"each\",\n    value: function each(func) {\n      return this.tap().map(function (a) {\n        return Promise.resolve(func(a)).then(function () {\n          return a;\n        });\n      }).resume();\n    }\n    /**\n     * Reads the stream while the function outcome is truthy.\n     *\n     * Stops reading and emits end as soon as it finds the first chunk that evaluates\n     * to false. If you're processing a file until a certain point or you just need to\n     * confirm existence of some data, you can use it to end the stream before reaching end.\n     *\n     * Keep in mind that whatever you piped to the stream will still need to be handled.\n     *\n     * @chainable\n     * @param  {FilterCallback} func The condition check\n     *\n     * @test test/methods/data-stream-while.js\n     */\n\n  }, {\n    key: \"while\",\n    value: function _while(func) {\n      var _this3 = this;\n\n      var condition = true;\n\n      var out = this._selfInstance();\n\n      return this.tap().pipe(out.filter(function (chunk) {\n        var result = condition && func(chunk);\n\n        if (condition != result) {\n          condition = result;\n\n          _this3.unpipe(out);\n\n          out.end();\n        }\n\n        return Promise.resolve(result).then(function (result) {\n          return result ? chunk : Promise.reject(DataStream.filter);\n        });\n      }));\n    }\n    /**\n     * Reads the stream until the function outcome is truthy.\n     *\n     * Works opposite of while.\n     *\n     * @chainable\n     * @param  {FilterCallback} func The condition check\n     *\n     * @test test/methods/data-stream-until.js\n     */\n\n  }, {\n    key: \"until\",\n    value: function until(func) {\n      var _this4 = this;\n\n      var condition = false;\n\n      var out = this._selfInstance();\n\n      return this.tap().pipe(out).filter(function (chunk) {\n        var result = condition || func(chunk);\n        var ref = !result ? chunk : Promise.reject(DataStream.filter);\n\n        if (condition != result) {\n          condition = result;\n\n          _this4.unpipe(out);\n\n          out.end();\n        }\n\n        return ref;\n      });\n    }\n    /**\n     * Provides a way to catch errors in chained streams.\n     *\n     * The handler will be called as asynchronous\n     *  - if it resolves then the error will be muted.\n     *  - if it rejects then the error will be passed to the next handler\n     *\n     * If no handlers will resolve the error, an `error` event will be emitted\n     *\n     * @chainable\n     * @name catch\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {Function} callback Error handler (async function)\n     *\n     * @test test/methods/data-stream-catch.js\n     */\n\n    /**\n     * Executes all error handlers and if none resolves, then emits an error.\n     *\n     * The returned promise will always be resolved even if there are no successful handlers.\n     *\n     * @async\n     * @name raise\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {Error} err The thrown error\n     *\n     * @test test/methods/data-stream-raise.js\n     */\n\n    /**\n     * Override of node.js Readable pipe.\n     *\n     * Except for calling overridden method it proxies errors to piped stream.\n     *\n     * @name pipe\n     * @chainable\n     * @ignore\n     * @method\n     * @memberof module:scramjet.DataStream#\n     * @param  {NodeJS.WritableStream} to  Writable stream to write to\n     * @param  {WritableOptions} [options={}]\n     * @return {NodeJS.WritableStream}  the `to` stream\n     */\n\n    /**\n     * Creates a BufferStream.\n     *\n     * The passed serializer must return a buffer.\n     *\n     * @meta.noReadme\n     * @chainable\n     * @param  {MapCallback} serializer A method that converts chunks to buffers\n     * @return {BufferStream}  the resulting stream\n     *\n     * @test test/methods/data-stream-tobufferstream.js\n     */\n\n  }, {\n    key: \"bufferify\",\n    value: function bufferify(serializer) {\n      return this.map(serializer, scramjet.BufferStream);\n    }\n    /**\n     * Creates a StringStream.\n     *\n     * The passed serializer must return a string. If no serializer is passed chunks\n     * toString method will be used.\n     *\n     * @chainable\n     * @param  {MapCallback|never} [serializer] A method that converts chunks to strings\n     * @return {StringStream} the resulting stream\n     *\n     * @test test/methods/data-stream-tostringstream.js\n     */\n\n  }, {\n    key: \"stringify\",\n    value: function stringify() {\n      var serializer = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : function (a) {\n        return \"\".concat(a);\n      };\n      return this.map(serializer, scramjet.StringStream);\n    }\n    /**\n     * Create a DataStream from an Array\n     *\n     * @param  {Array<*>} array list of chunks\n     * @param {DataStreamOptions} [options={}] the read stream options\n     * @return {DataStream}\n     *\n     * @test test/methods/data-stream-fromarray.js\n     */\n\n  }, {\n    key: \"toArray\",\n    value:\n    /**\n     * Aggregates the stream into a single Array\n     *\n     * In fact it's just a shorthand for reducing the stream into an Array.\n     *\n     * @async\n     * @param  {Array} [initial=[]] Array to begin with (defaults to an empty array).\n     * @returns {any[]}\n     */\n    function toArray() {\n      var initial = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n      return this.reduce(function (arr, item) {\n        return arr.push(item), arr;\n      }, initial);\n    }\n    /**\n     * Returns an async generator\n     *\n     * @return {Generator<Promise<any>>} Returns an iterator that returns a promise for each item.\n     */\n\n  }, {\n    key: \"toGenerator\",\n    value: function toGenerator() {\n      this.tap();\n      var ref = this;\n      return /*#__PURE__*/_regeneratorRuntime.mark(function _callee5() {\n        var ended;\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                ended = false;\n                ref.on(\"end\", function () {\n                  return ended = true;\n                });\n\n              case 2:\n                if (ended) {\n                  _context5.next = 7;\n                  break;\n                }\n\n                _context5.next = 5;\n                return ref.whenRead();\n\n              case 5:\n                _context5.next = 2;\n                break;\n\n              case 7:\n                return _context5.abrupt(\"return\");\n\n              case 8:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5);\n      });\n    }\n    /**\n     * Returns a new instance of self.\n     *\n     * Normally this doesn't have to be overridden.\n     * When the constructor would use some special arguments this may be used to\n     * override the object construction in {@link tee}...\n     *\n     * @meta.noReadme\n     * @memberof module:scramjet.DataStream#\n     * @name _selfInstance\n     * @method\n     * @return {DataStream}  an empty instance of the same class.\n     * @test test/methods/data-stream-selfinstance.js\n     */\n\n  }], [{\n    key: \"from\",\n    value: function from(input, options) {\n      var _this5 = this;\n\n      var target = options instanceof this && options;\n      var StreamError = scramjet.errors.StreamError;\n\n      if (input instanceof this) {\n        return target ? input.pipe(target) : input;\n      }\n\n      if (input instanceof Readable || typeof input.readable === \"boolean\" && typeof input.pipe === \"function\" && typeof input.on === \"function\") {\n        var out = target || new this(Object.assign({}, options, {\n          referrer: input instanceof DataStream ? input : null\n        }));\n        input.pipe(out);\n        input.on(\"error\", function (e) {\n          return out.raise(e);\n        });\n        return out;\n      }\n\n      for (var _len2 = arguments.length, args = new Array(_len2 > 2 ? _len2 - 2 : 0), _key2 = 2; _key2 < _len2; _key2++) {\n        args[_key2 - 2] = arguments[_key2];\n      }\n\n      if (input instanceof GeneratorFunction || input instanceof AsyncGeneratorFunction) {\n        var iterator = input.apply(void 0, args);\n        var iteratorStream = this.fromIterator(iterator, options);\n        return pipeIfTarget(iteratorStream, target);\n      }\n\n      if (Array.isArray(input)) return pipeIfTarget(this.fromArray(input, options), target);\n      var iter = input[Symbol.iterator] || Symbol.asyncIterator && input[Symbol.asyncIterator];\n\n      if (iter) {\n        try {\n          var _iterator = iter.call(input);\n\n          return pipeIfTarget(this.fromIterator(_iterator, options), target);\n        } catch (e) {\n          var _out = target || new this();\n\n          _out.raise(new StreamError(e, _out, \"EXTERNAL\", null));\n\n          return _out;\n        }\n      }\n\n      if (input instanceof Promise) {\n        var _out2 = new this(Object.assign({}, options));\n\n        input.then(function (source) {\n          return _this5.from(source, _out2);\n        }).catch(function (e) {\n          return _out2.raise(new StreamError(e, _out2, \"EXTERNAL\", null));\n        });\n        return _out2;\n      }\n\n      if (typeof input === \"function\") {\n        var _out3 = new this(Object.assign({}, options));\n\n        Promise.resolve(options).then(input).then(function (source) {\n          return _this5.from(source, _out3);\n        }).catch(function (e) {\n          return _out3.raise(new StreamError(e, _out3, \"EXTERNAL\", null));\n        });\n        return _out3;\n      }\n\n      if (typeof input === \"string\") {\n        var _DataStream;\n\n        return (_DataStream = new DataStream([])).use.apply(_DataStream, [input].concat(args));\n      }\n\n      throw new Error(\"Cannot return a stream from passed object\");\n    }\n  }, {\n    key: \"pipeline\",\n    value: function pipeline(readable) {\n      var _this6 = this;\n\n      for (var _len3 = arguments.length, transforms = new Array(_len3 > 1 ? _len3 - 1 : 0), _key3 = 1; _key3 < _len3; _key3++) {\n        transforms[_key3 - 1] = arguments[_key3];\n      }\n\n      var out = new this();\n      var current = this.from(readable);\n\n      _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6() {\n        var _iterator2, _step, transform;\n\n        return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                _iterator2 = _createForOfIteratorHelper(transforms);\n\n                try {\n                  for (_iterator2.s(); !(_step = _iterator2.n()).done;) {\n                    transform = _step.value;\n\n                    if (transform instanceof Transform || typeof transform.readable === \"boolean\" && transform.readable && typeof transform.writable === \"boolean\" && transform.writable && typeof transform.pipe === \"function\" && typeof transform.on === \"function\") {\n                      current = _this6.from(current.pipe(transform));\n                    } else {\n                      current = _this6.from(current).use(transform);\n                    }\n                  }\n                } catch (err) {\n                  _iterator2.e(err);\n                } finally {\n                  _iterator2.f();\n                }\n\n                _this6.from(current).pipe(out);\n\n              case 3:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6);\n      }))().then().catch(function (e) {\n        return out.raise(e);\n      });\n\n      return out;\n    }\n  }, {\n    key: \"fromArray\",\n    value: function fromArray(array) {\n      var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n      var ret = new this(options);\n      array = array.slice();\n      array.forEach(function (item) {\n        return ret.write(item);\n      });\n      ret.end();\n      return ret;\n    }\n    /**\n     * Create a DataStream from an Iterator\n     *\n     * Doesn't end the stream until it reaches end of the iterator.\n     *\n     * @param {Iterator<any>} iterator the iterator object\n     * @param {DataStreamOptions} [options={}] the read stream options\n     * @return {DataStream}\n     *\n     * @test test/methods/data-stream-fromiterator.js\n     */\n\n  }, {\n    key: \"fromIterator\",\n    value: function fromIterator(iterator, options) {\n      return new this(Object.assign({}, options, {\n        // TODO: handle count argument\n        // problem here is how do we know which promises are resolved and until where?\n        // need to queue a number of promises up to maxParallel, but push them with\n        // Promise.all with the previous one.\n        parallelRead: function parallelRead() {\n          return _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee7() {\n            var read;\n            return _regeneratorRuntime.wrap(function _callee7$(_context7) {\n              while (1) {\n                switch (_context7.prev = _context7.next) {\n                  case 0:\n                    _context7.next = 2;\n                    return iterator.next();\n\n                  case 2:\n                    read = _context7.sent;\n\n                    if (!read.done) {\n                      _context7.next = 15;\n                      break;\n                    }\n\n                    if (!read.value) {\n                      _context7.next = 11;\n                      break;\n                    }\n\n                    _context7.next = 7;\n                    return read.value;\n\n                  case 7:\n                    _context7.t1 = _context7.sent;\n                    _context7.t0 = [_context7.t1, null];\n                    _context7.next = 12;\n                    break;\n\n                  case 11:\n                    _context7.t0 = [null];\n\n                  case 12:\n                    return _context7.abrupt(\"return\", _context7.t0);\n\n                  case 15:\n                    _context7.next = 17;\n                    return read.value;\n\n                  case 17:\n                    _context7.t2 = _context7.sent;\n                    return _context7.abrupt(\"return\", [_context7.t2]);\n\n                  case 19:\n                  case \"end\":\n                    return _context7.stop();\n                }\n              }\n            }, _callee7);\n          }))();\n        }\n      }));\n    }\n  }]);\n\n  return DataStream;\n}(PromiseTransformStream);\n/**\n * Transform async callback. The passed transform should return a new chunk, unless\n * the output should be filtered - if so, the transform should return `undefined`.\n *\n * Additionally the function can reject with `DataStream.filter` - the result will be\n * filtered and no other transforms will be run on the chunk.\n *\n * @callback ScramjetTransformCallback\n * @memberof module:scramjet~\n * @param {Buffer|string|any} chunk the stream chunk\n * @param {string} encoding encoding of the chunk\n * @returns {Promise<any|undefined>|any|undefined} the result, undefined will be treated as filtered out.\n */\n\n/**\n * Write async callback. Await your async write and resolve.\n *\n * @callback ScramjetWriteCallback\n * @memberof module:scramjet~\n * @param {Buffer|string|any} chunk the stream chunk\n * @param {string} encoding encoding of the chunk\n * @returns {Promise<void>|void} should resolve when the write ends\n */\n\n/**\n * Read async callback. Simply await your async operations and return the result as array.\n *\n * @callback ScramjetReadCallback\n * @memberof module:scramjet~\n * @param {number} count the number of chunks that should be read (\"this is more like a set of guideline than actual rules\").\n * @returns {Array<any>|Promise<Array<any>>} the read chunk.\n */\n\n/**\n * Standard options for scramjet streams.\n *\n * Defines async transforms or read/write methods for a stream.\n * @typedef {object} DataStreamOptions\n * @memberof module:scramjet~\n * @property {ScramjetReadCallback} [promiseRead=null] an async function returning the next read item\n * @property {ScramjetWriteCallback} [promiseWrite=null] an async function writing the next written item\n * @property {ScramjetTransformCallback} [promiseTransform=null] an async function returning a transformed chunk\n * @property {ScramjetReadCallback} [promiseFlush=null] an async function run before transform stream ends to push last chunks from the buffer\n * @property {ScramjetTransformCallback} [beforeTransform=null] an async function run before the transform\n * @property {ScramjetTransformCallback} [afterTransform=null] an async function run after the transform\n * @property {number} [maxParallel=os.cpus.length*2] the number of transforms done in parallel\n * @property {DataStream} [referrer=null] a referring stream to point to (if possible the transforms will be pushed to it\n * @property {boolean} [objectMode=true] should the object mode be used instead of creating a new stream)\n * @property {number} [highWaterMark] The maximum number of bytes to store in the internal buffer before ceasing to read from the underlying resource. Default: 16384 (16KB), or 16 for objectMode streams.\n * @property {string} [encoding] If specified, then buffers will be decoded to strings using the specified encoding. Default: null.\n * @property {boolean} [emitClose] Whether or not the stream should emit 'close' after it has been destroyed. Default: true.\n * @property {Function} [read] Implementation for the stream._read() method.\n * @property {Function} [destroy] Implementation for the stream._destroy() method.\n * @property {Function} [construct] Implementation for the stream._construct() method.\n * @property {boolean} [autoDestroy] Whether this stream should automatically call .destroy() on itself after ending. Default: true.\n */\n\n\nDataStream.prototype.toBufferStream = DataStream.prototype.bufferify;\nDataStream.prototype.toStringStream = DataStream.prototype.stringify;\nmodule.exports = DataStream;","map":{"version":3,"sources":["/Users/samehrlich/Desktop/final-app/client/node_modules/scramjet-core/lib/data-stream.js"],"names":["require","PromiseTransformStream","Readable","Writable","Transform","scramjet","AsyncGeneratorFunction","GeneratorFunction","resolveCalleeBlackboxed","pipeIfTarget","DataStream","opts","Object","assign","objectMode","writableObjectMode","readableObjectMode","func","ClassType","constructor","pipe","promiseTransform","referrer","_selfInstance","afterTransform","chunk","ret","Promise","reject","filter","into","last","resolve","tap","then","acc","initial","resume","whenFinished","map","functions","chunkPromise","all","race","waiting","processing","Array","_options","maxParallel","fill","out","each","slot","findIndex","x","length","res","push","result","whenWrote","next","shift","run","end","Error","setOptions","catch","e","raise","on","startsWith","readable","writable","from","parameters","whenEnd","a","condition","unpipe","ref","serializer","BufferStream","StringStream","reduce","arr","item","ended","whenRead","input","options","target","StreamError","errors","args","iterator","iteratorStream","fromIterator","isArray","fromArray","iter","Symbol","asyncIterator","call","source","use","transforms","current","transform","array","slice","forEach","write","parallelRead","read","done","value","prototype","toBufferStream","bufferify","toStringStream","stringify","module","exports"],"mappings":";;;;;;;;;;;;;;AAAA,eAAiCA,OAAO,CAAC,iCAAD,CAAxC;AAAA,IAAOC,sBAAP,YAAOA,sBAAP;;AACA,gBAAwCD,OAAO,CAAC,QAAD,CAA/C;AAAA,IAAOE,QAAP,aAAOA,QAAP;AAAA,IAAiBC,QAAjB,aAAiBA,QAAjB;AAAA,IAA2BC,SAA3B,aAA2BA,SAA3B;;AACA,IAAMC,QAAQ,GAAGL,OAAO,CAAC,GAAD,CAAxB;;AAEA,gBAKIA,OAAO,CAAC,cAAD,CALX;AAAA,IACIM,sBADJ,aACIA,sBADJ;AAAA,IAEIC,iBAFJ,aAEIA,iBAFJ;AAAA,IAGIC,uBAHJ,aAGIA,uBAHJ;AAAA,IAIIC,YAJJ,aAIIA,YAJJ;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;IACMC,U;;;;;;;AAEF;AACJ;AACA;AACA;AACA;AACA;AACA;AACI,sBAAYC,IAAZ,EAAkB;AAAA;;AAAA,6BACRC,MAAM,CAACC,MAAP,CAAc;AAChBC,MAAAA,UAAU,EAAE,IADI;AAEhBC,MAAAA,kBAAkB,EAAE,IAFJ;AAGhBC,MAAAA,kBAAkB,EAAE;AAHJ,KAAd,EAIHL,IAJG,CADQ;AAMjB;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;AA8EI;AACJ;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACI,iBAAIM,IAAJ,EAAwC;AAAA,UAA9BC,SAA8B,uEAAlB,KAAKC,WAAa;AACpC,aAAO,KAAKC,IAAL,CAAU,IAAIF,SAAJ,CAAc;AAC3BG,QAAAA,gBAAgB,EAAEJ,IADS;AAE3BK,QAAAA,QAAQ,EAAE;AAFiB,OAAd,CAAV,CAAP;AAIH;AAED;AACJ;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,gBAAOL,IAAP,EAAa;AACT,aAAO,KAAKG,IAAL,CAAU,KAAKG,aAAL,CAAmB;AAChCF,QAAAA,gBAAgB,EAAEJ,IADc;AAEhCO,QAAAA,cAAc,EAAE,wBAACC,KAAD,EAAQC,GAAR;AAAA,iBAAgBA,GAAG,GAAGD,KAAH,GAAWE,OAAO,CAACC,MAAR,CAAelB,UAAU,CAACmB,MAA1B,CAA9B;AAAA,SAFgB;AAGhCP,QAAAA,QAAQ,EAAE;AAHsB,OAAnB,CAAV,CAAP;AAKH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,gBAAOL,IAAP,EAAaa,IAAb,EAAmB;AAEf,UAAIC,IAAI,GAAGJ,OAAO,CAACK,OAAR,CAAgBF,IAAhB,CAAX;AAEA,aAAO,KAAKG,GAAL,GACFb,IADE,CACG,IAAInB,sBAAJ,CAA2B;AAC7BoB,QAAAA,gBAAgB,EAAE,0BAACI,KAAD,EAAW;AACzB,iBAAOM,IAAI,GAAGA,IAAI,CAACG,IAAL,CAAU,UAACC,GAAD;AAAA,mBAASlB,IAAI,CAACkB,GAAD,EAAMV,KAAN,CAAb;AAAA,WAAV,CAAd;AACH,SAH4B;AAI7BH,QAAAA,QAAQ,EAAE,IAJmB;AAK7Bc,QAAAA,OAAO,EAAEN;AALoB,OAA3B,CADH,EAQFO,MARE,GASFC,YATE,GAUFJ,IAVE,CAUG;AAAA,eAAMH,IAAN;AAAA,OAVH,CAAP;AAWH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,aAAGd,IAAH,EAAS;AACL,aAAO,KAAKsB,GAAL;AAAA,4EAAS,iBAAOd,KAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAAwBR,IAAI,CAACQ,KAAD,CAA5B;;AAAA;AAAA,mDAAqCA,KAArC;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAAT;;AAAA;AAAA;AAAA;AAAA,UAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,aAAIe,SAAJ,EAAe;AACX,aAAO,KAAKD,GAAL,CAAS,UAAAd,KAAK,EAAI;AACrB,YAAMgB,YAAY,GAAGd,OAAO,CAACK,OAAR,CAAgBP,KAAhB,CAArB;AACA,eAAOE,OAAO,CAACe,GAAR,CAAYF,SAAS,CAACD,GAAV,CAAc,UAAAtB,IAAI;AAAA,iBAAIwB,YAAY,CAACP,IAAb,CAAkBjB,IAAlB,CAAJ;AAAA,SAAlB,CAAZ,CAAP;AACH,OAHM,CAAP;AAIH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,cAAKuB,SAAL,EAAgB;AACZ,aAAO,KAAKD,GAAL,CAAS,UAAAd,KAAK,EAAI;AACrB,YAAMgB,YAAY,GAAGd,OAAO,CAACK,OAAR,CAAgBP,KAAhB,CAArB;AACA,eAAOE,OAAO,CAACgB,IAAR,CAAaH,SAAS,CAACD,GAAV,CAAc,UAAAtB,IAAI;AAAA,iBAAIwB,YAAY,CAACP,IAAb,CAAkBjB,IAAlB,CAAJ;AAAA,SAAlB,CAAb,CAAP;AACH,OAHM,CAAP;AAIH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,iBAAQA,IAAR,EAAc;AAAA;;AACV,UAAM2B,OAAO,GAAG,EAAhB;AACA,UAAMC,UAAU,GAAGC,KAAK,CAAC,KAAKC,QAAL,CAAcC,WAAf,CAAL,CAAiCC,IAAjC,CAAsC,IAAtC,CAAnB;;AACA,UAAMC,GAAG,GAAG,KAAK3B,aAAL,CAAmB;AAACD,QAAAA,QAAQ,EAAE;AAAX,OAAnB,CAAZ;;AAEA,WACK6B,IADL;AAAA,6EACU,kBAAM1B,KAAN;AAAA;AAAA;AAAA;AAAA;AAAA;AACF;;AACA;AACI2B,kBAAAA,IAHF,GAGSP,UAAU,CAACQ,SAAX,CAAqB,UAAAC,CAAC;AAAA,2BAAIA,CAAC,KAAK,IAAV;AAAA,mBAAtB,CAHT;AAIF,sBAAIF,IAAI,GAAG,CAAP,IAAYP,UAAU,CAACU,MAAX,GAAoB,KAAI,CAACR,QAAL,CAAcC,WAAlD,EAA+DI,IAAI,GAAGP,UAAU,CAACU,MAAlB;;AAJ7D,wBAKEH,IAAI,GAAG,CALT;AAAA;AAAA;AAAA;;AAAA;AAAA,yBAKyB,IAAIzB,OAAJ,CAAY,UAAA6B,GAAG;AAAA,2BAAIZ,OAAO,CAACa,IAAR,CAAaD,GAAb,CAAJ;AAAA,mBAAf,CALzB;;AAAA;AAKYJ,kBAAAA,IALZ;;AAAA;AAOFP,kBAAAA,UAAU,CAACO,IAAD,CAAV,GAAmBzB,OAAO,CACrBK,OADc,CACNP,KADM,EAEdS,IAFc,CAETjB,IAFS,EAGdiB,IAHc,CAGT,UAAAwB,MAAM;AAAA,2BAAIR,GAAG,CAACS,SAAJ,CAAcD,MAAd,CAAJ;AAAA,mBAHG,EAIdxB,IAJc,CAIT,YAAM;AACR,wBAAM0B,IAAI,GAAGhB,OAAO,CAACiB,KAAR,EAAb;AACA,wBAAID,IAAJ,EAAUA,IAAI,CAACR,IAAD,CAAJ,CAAV,KACKP,UAAU,CAACO,IAAD,CAAV,GAAmB,IAAnB;AACR,mBARc,CAAnB;AASA;;AAhBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SADV;;AAAA;AAAA;AAAA;AAAA,WAmBKU,GAnBL,GAoBK5B,IApBL,CAoBU;AAAA,eAAMP,OAAO,CAACe,GAAR,CAAYG,UAAZ,CAAN;AAAA,OApBV,EAqBKX,IArBL,CAqBU;AAAA,eAAMgB,GAAG,CAACa,GAAJ,EAAN;AAAA,OArBV;AAuBA,aAAOb,GAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,cAAKjC,IAAL,EAAWa,KAAX,EAAiB;AACb,UAAI,EAAEA,KAAI,YAAYpB,UAAlB,CAAJ,EAAmC,MAAM,IAAIsD,KAAJ,CAAU,wBAAV,CAAN;AAEnC,UAAI,CAAClC,KAAI,CAACiB,QAAL,CAAczB,QAAnB,EACIQ,KAAI,CAACmC,UAAL,CAAgB;AAAC3C,QAAAA,QAAQ,EAAE;AAAX,OAAhB;AAEJ,WAAKW,GAAL,GACKiC,KADL,CACW,UAAAC,CAAC;AAAA,eAAIrC,KAAI,CAACsC,KAAL,CAAWD,CAAX,CAAJ;AAAA,OADZ,EAEK/C,IAFL,CAEU,IAAK,KAAKD,WAAV,CAAuB;AACzBE,QAAAA,gBAAgB;AAAA,2FAAE,kBAAOI,KAAP;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAEJR,IAAI,CAACa,KAAD,EAAOL,KAAP,CAFA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAIVK,oBAAAA,KAAI,CAACsC,KAAL;;AAJU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,WAAF;;AAAA;AAAA;AAAA;;AAAA;AAAA,WADS;AAQzB9C,QAAAA,QAAQ,EAAE;AARe,OAAvB,CAFV,EAYK+C,EAZL,CAYQ,KAZR,EAYe;AAAA,eAAMvC,KAAI,CAACiC,GAAL,EAAN;AAAA,OAZf,EAaK1B,MAbL;AAeA,aAAOP,KAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,aAAIb,IAAJ,EAAyB;AAAA;;AACrB,UAAI,OAAOA,IAAP,IAAe,QAAnB,EAA6B;AACzBA,QAAAA,IAAI,GAAGjB,OAAO,CAACiB,IAAI,CAACqD,UAAL,CAAgB,GAAhB,IAAuB9D,uBAAuB,CAACS,IAAD,CAA9C,GAAuDA,IAAxD,CAAd;AACH;;AAED,UAAIA,IAAI,YAAYb,SAAhB,IACA,OAAOa,IAAI,CAACsD,QAAZ,KAAyB,SAAzB,IAAsCtD,IAAI,CAACsD,QAA3C,IACA,OAAOtD,IAAI,CAACuD,QAAZ,KAAyB,SADzB,IACsCvD,IAAI,CAACuD,QAD3C,IAEA,OAAOvD,IAAI,CAACG,IAAZ,KAAqB,UAFrB,IAGA,OAAOH,IAAI,CAACoD,EAAZ,KAAmB,UAJvB,EAKG;AACC,eAAO,KAAKlD,WAAL,CAAiBsD,IAAjB,CAAsB,KAAKrD,IAAL,CAAUH,IAAV,CAAtB,CAAP;AACH;;AAZoB,wCAAZyD,UAAY;AAAZA,QAAAA,UAAY;AAAA;;AAcrB,UAAIzD,IAAI,YAAYV,iBAAhB,IAAqCU,IAAI,YAAYX,sBAAzD,EAAiF;AAAA;;AAC7E,eAAO,0BAAKa,WAAL,EAAiBsD,IAAjB,2BAAsBxD,IAAtB,EAA4B,EAA5B,EAAgC,IAAhC,SAAyCyD,UAAzC,EAAP;AACH;;AAED,UAAI,OAAOzD,IAAP,KAAgB,UAApB,EAAgC;AAC5B,YAAMyC,MAAM,GAAGzC,IAAI,MAAJ,UAAK,IAAL,SAAcyD,UAAd,EAAf;;AACA,YAAIhB,MAAM,YAAY/B,OAAtB,EAA+B;AAC3B,cAAMuB,GAAG,GAAG,IAAI,KAAK/B,WAAT,EAAZ;AACAuC,UAAAA,MAAM,CACDxB,IADL,CACU,UAAAsB,GAAG;AAAA,mBAAI,MAAI,CAACrC,WAAL,CAAiBsD,IAAjB,CAAsBjB,GAAtB,EAA2BpC,IAA3B,CAAgC8B,GAAhC,CAAJ;AAAA,WADb,EAEKgB,KAFL,CAEW,UAAAC,CAAC;AAAA,mBAAIjB,GAAG,CAACkB,KAAJ,CAAUD,CAAV,CAAJ;AAAA,WAFZ;AAIA,iBAAOjB,GAAP;AACH,SAPD,MAOO;AACH,iBAAOQ,MAAP;AACH;AACJ;;AAED,YAAM,IAAIM,KAAJ,CAAU,wBAAV,CAAN;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;0EACI;AAAA;AAAA;AAAA;AAAA;AAAA,kDACW,KAAK/B,GAAL,GACFb,IADE,CACG,IAAIV,UAAJ,EADH,EAEF2D,EAFE,CAEC,MAFD,EAES;AAAA,yBAAM,CAAN;AAAA,iBAFT,EAGFM,OAHE,EADX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAOA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AAgCI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACI,oBAAO;AACH,aAAO,KAAK1C,GAAL,GAAWb,IAAX,CAAgB,KAAKG,aAAL,EAAhB,CAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,aAAIN,IAAJ,EAAU;AACN,UAAIA,IAAI,YAAYd,QAApB,EACI,OAAQ,KAAK8B,GAAL,GAAWb,IAAX,CAAgBH,IAAhB,GAAuB,IAA/B;AACJA,MAAAA,IAAI,CAAC,KAAKG,IAAL,CAAU,KAAKG,aAAL,EAAV,CAAD,CAAJ;AACA,aAAO,KAAKU,GAAL,EAAP;AACH;AAED;AACJ;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,cAAKhB,IAAL,EAAW;AACP,aAAO,KAAKgB,GAAL,GAAWM,GAAX,CACH,UAACqC,CAAD;AAAA,eAAOjD,OAAO,CAACK,OAAR,CAAgBf,IAAI,CAAC2D,CAAD,CAApB,EACF1C,IADE,CACG;AAAA,iBAAM0C,CAAN;AAAA,SADH,CAAP;AAAA,OADG,EAGLvC,MAHK,EAAP;AAIH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,gBAAMpB,IAAN,EAAY;AAAA;;AACR,UAAI4D,SAAS,GAAG,IAAhB;;AACA,UAAM3B,GAAG,GAAG,KAAK3B,aAAL,EAAZ;;AACA,aAAO,KAAKU,GAAL,GAAWb,IAAX,CAAgB8B,GAAG,CAACrB,MAAJ,CACnB,UAACJ,KAAD,EAAW;AACP,YAAMiC,MAAM,GAAGmB,SAAS,IAAI5D,IAAI,CAACQ,KAAD,CAAhC;;AACA,YAAIoD,SAAS,IAAInB,MAAjB,EAAyB;AACrBmB,UAAAA,SAAS,GAAGnB,MAAZ;;AACA,UAAA,MAAI,CAACoB,MAAL,CAAY5B,GAAZ;;AACAA,UAAAA,GAAG,CAACa,GAAJ;AACH;;AAED,eAAOpC,OAAO,CACTK,OADE,CACM0B,MADN,EAEFxB,IAFE,CAEG,UAAAwB,MAAM;AAAA,iBAAIA,MAAM,GAAGjC,KAAH,GAAWE,OAAO,CAACC,MAAR,CAAelB,UAAU,CAACmB,MAA1B,CAArB;AAAA,SAFT,CAAP;AAGH,OAZkB,CAAhB,CAAP;AAcH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,eAAMZ,IAAN,EAAY;AAAA;;AACR,UAAI4D,SAAS,GAAG,KAAhB;;AACA,UAAM3B,GAAG,GAAG,KAAK3B,aAAL,EAAZ;;AACA,aAAO,KAAKU,GAAL,GAAWb,IAAX,CAAgB8B,GAAhB,EAAqBrB,MAArB,CACH,UAACJ,KAAD,EAAW;AACP,YAAMiC,MAAM,GAAGmB,SAAS,IAAI5D,IAAI,CAACQ,KAAD,CAAhC;AACA,YAAMsD,GAAG,GAAG,CAACrB,MAAD,GAAUjC,KAAV,GAAkBE,OAAO,CAACC,MAAR,CAAelB,UAAU,CAACmB,MAA1B,CAA9B;;AAEA,YAAIgD,SAAS,IAAInB,MAAjB,EAAyB;AACrBmB,UAAAA,SAAS,GAAGnB,MAAZ;;AACA,UAAA,MAAI,CAACoB,MAAL,CAAY5B,GAAZ;;AACAA,UAAAA,GAAG,CAACa,GAAJ;AACH;;AAED,eAAOgB,GAAP;AACH,OAZE,CAAP;AAcH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,mBAAUC,UAAV,EAAsB;AAClB,aAAO,KAAKzC,GAAL,CAASyC,UAAT,EAAqB3E,QAAQ,CAAC4E,YAA9B,CAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,qBAAoC;AAAA,UAA1BD,UAA0B,uEAAb,UAAAJ,CAAC;AAAA,yBAAOA,CAAP;AAAA,OAAY;AAChC,aAAO,KAAKrC,GAAL,CAASyC,UAAT,EAAqB3E,QAAQ,CAAC6E,YAA9B,CAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AAqCI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACI,uBAAsB;AAAA,UAAd9C,OAAc,uEAAJ,EAAI;AAClB,aAAO,KAAK+C,MAAL,CACH,UAACC,GAAD,EAAMC,IAAN;AAAA,eAAgBD,GAAG,CAAC3B,IAAJ,CAAS4B,IAAT,GAAgBD,GAAhC;AAAA,OADG,EAEHhD,OAFG,CAAP;AAIH;AAED;AACJ;AACA;AACA;AACA;;;;WACI,uBAAc;AACV,WAAKH,GAAL;AACA,UAAM8C,GAAG,GAAG,IAAZ;AACA,mDAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AACCO,gBAAAA,KADD,GACS,KADT;AAEHP,gBAAAA,GAAG,CAACV,EAAJ,CAAO,KAAP,EAAc;AAAA,yBAAMiB,KAAK,GAAG,IAAd;AAAA,iBAAd;;AAFG;AAAA,oBAGKA,KAHL;AAAA;AAAA;AAAA;;AAAA;AAIC,uBAAMP,GAAG,CAACQ,QAAJ,EAAN;;AAJD;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAP;AAQH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WAj0BI,cAAYC,KAAZ,EAAmBC,OAAnB,EAAqC;AAAA;;AACjC,UAAMC,MAAM,GAAGD,OAAO,YAAY,IAAnB,IAA2BA,OAA1C;AAEA,UAAgBE,WAAhB,GAAgCtF,QAAhC,CAAOuF,MAAP,CAAgBD,WAAhB;;AAEA,UAAIH,KAAK,YAAY,IAArB,EAA2B;AACvB,eAAOE,MAAM,GAAGF,KAAK,CAACpE,IAAN,CAAWsE,MAAX,CAAH,GAAwBF,KAArC;AACH;;AAED,UAAIA,KAAK,YAAYtF,QAAjB,IACA,OAAOsF,KAAK,CAACjB,QAAb,KAA0B,SAA1B,IACA,OAAOiB,KAAK,CAACpE,IAAb,KAAsB,UADtB,IAEA,OAAOoE,KAAK,CAACnB,EAAb,KAAoB,UAHxB,EAIG;AACC,YAAMnB,GAAG,GAAGwC,MAAM,IAAI,IAAI,IAAJ,CAClB9E,MAAM,CAACC,MAAP,CACI,EADJ,EAEI4E,OAFJ,EAGI;AAAEnE,UAAAA,QAAQ,EAAEkE,KAAK,YAAY9E,UAAjB,GAA8B8E,KAA9B,GAAsC;AAAlD,SAHJ,CADkB,CAAtB;AAQAA,QAAAA,KAAK,CAACpE,IAAN,CAAW8B,GAAX;AACAsC,QAAAA,KAAK,CAACnB,EAAN,CAAS,OAAT,EAAkB,UAAAF,CAAC;AAAA,iBAAIjB,GAAG,CAACkB,KAAJ,CAAUD,CAAV,CAAJ;AAAA,SAAnB;AACA,eAAOjB,GAAP;AACH;;AAzBgC,yCAAN2C,IAAM;AAANA,QAAAA,IAAM;AAAA;;AA2BjC,UAAIL,KAAK,YAAYjF,iBAAjB,IAAsCiF,KAAK,YAAYlF,sBAA3D,EAAmF;AAC/E,YAAMwF,QAAQ,GAAGN,KAAK,MAAL,SAASK,IAAT,CAAjB;AACA,YAAME,cAAc,GAAG,KAAKC,YAAL,CAAkBF,QAAlB,EAA4BL,OAA5B,CAAvB;AACA,eAAOhF,YAAY,CAACsF,cAAD,EAAiBL,MAAjB,CAAnB;AACH;;AAED,UAAI5C,KAAK,CAACmD,OAAN,CAAcT,KAAd,CAAJ,EACI,OAAO/E,YAAY,CAAC,KAAKyF,SAAL,CAAeV,KAAf,EAAsBC,OAAtB,CAAD,EAAiCC,MAAjC,CAAnB;AAEJ,UAAMS,IAAI,GAAGX,KAAK,CAACY,MAAM,CAACN,QAAR,CAAL,IAA2BM,MAAM,CAACC,aAAP,IAAwBb,KAAK,CAACY,MAAM,CAACC,aAAR,CAArE;;AACA,UAAIF,IAAJ,EAAU;AACN,YAAI;AACA,cAAML,SAAQ,GAAGK,IAAI,CAACG,IAAL,CAAUd,KAAV,CAAjB;;AACA,iBAAO/E,YAAY,CAAC,KAAKuF,YAAL,CAAkBF,SAAlB,EAA4BL,OAA5B,CAAD,EAAuCC,MAAvC,CAAnB;AACH,SAHD,CAGE,OAAMvB,CAAN,EAAS;AACP,cAAMjB,IAAG,GAAGwC,MAAM,IAAI,IAAI,IAAJ,EAAtB;;AACAxC,UAAAA,IAAG,CAACkB,KAAJ,CAAU,IAAIuB,WAAJ,CAAgBxB,CAAhB,EAAmBjB,IAAnB,EAAwB,UAAxB,EAAoC,IAApC,CAAV;;AAEA,iBAAOA,IAAP;AACH;AACJ;;AAED,UAAIsC,KAAK,YAAY7D,OAArB,EAA8B;AAC1B,YAAMuB,KAAG,GAAG,IAAI,IAAJ,CAAStC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB4E,OAAlB,CAAT,CAAZ;;AAEAD,QAAAA,KAAK,CACAtD,IADL,CACU,UAAAqE,MAAM;AAAA,iBAAI,MAAI,CAAC9B,IAAL,CAAU8B,MAAV,EAAkBrD,KAAlB,CAAJ;AAAA,SADhB,EAEKgB,KAFL,CAEW,UAAAC,CAAC;AAAA,iBAAIjB,KAAG,CAACkB,KAAJ,CAAU,IAAIuB,WAAJ,CAAgBxB,CAAhB,EAAmBjB,KAAnB,EAAwB,UAAxB,EAAoC,IAApC,CAAV,CAAJ;AAAA,SAFZ;AAIA,eAAOA,KAAP;AACH;;AAED,UAAI,OAAOsC,KAAP,KAAiB,UAArB,EAAiC;AAC7B,YAAMtC,KAAG,GAAG,IAAI,IAAJ,CAAStC,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB4E,OAAlB,CAAT,CAAZ;;AAEA9D,QAAAA,OAAO,CAACK,OAAR,CAAgByD,OAAhB,EACKvD,IADL,CACUsD,KADV,EAEKtD,IAFL,CAEU,UAAAqE,MAAM;AAAA,iBAAI,MAAI,CAAC9B,IAAL,CAAU8B,MAAV,EAAkBrD,KAAlB,CAAJ;AAAA,SAFhB,EAGKgB,KAHL,CAGW,UAAAC,CAAC;AAAA,iBAAIjB,KAAG,CAACkB,KAAJ,CAAU,IAAIuB,WAAJ,CAAgBxB,CAAhB,EAAmBjB,KAAnB,EAAwB,UAAxB,EAAoC,IAApC,CAAV,CAAJ;AAAA,SAHZ;AAKA,eAAOA,KAAP;AACH;;AAED,UAAI,OAAOsC,KAAP,KAAiB,QAArB,EAA+B;AAAA;;AAC3B,eAAO,mBAAI9E,UAAJ,CAAe,EAAf,GAAmB8F,GAAnB,qBAAuBhB,KAAvB,SAAiCK,IAAjC,EAAP;AACH;;AAED,YAAM,IAAI7B,KAAJ,CAAU,2CAAV,CAAN;AACH;;;WA+WD,kBAAgBO,QAAhB,EAAyC;AAAA;;AAAA,yCAAZkC,UAAY;AAAZA,QAAAA,UAAY;AAAA;;AACrC,UAAMvD,GAAG,GAAG,IAAI,IAAJ,EAAZ;AACA,UAAIwD,OAAO,GAAG,KAAKjC,IAAL,CAAUF,QAAV,CAAd;;AAEA,+DAAC;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,wDACyBkC,UADzB;;AAAA;AACG,wEAAkC;AAAzBE,oBAAAA,SAAyB;;AAC9B,wBAAIA,SAAS,YAAYvG,SAArB,IACA,OAAOuG,SAAS,CAACpC,QAAjB,KAA8B,SAA9B,IAA2CoC,SAAS,CAACpC,QAArD,IACA,OAAOoC,SAAS,CAACnC,QAAjB,KAA8B,SAD9B,IAC2CmC,SAAS,CAACnC,QADrD,IAEA,OAAOmC,SAAS,CAACvF,IAAjB,KAA0B,UAF1B,IAGA,OAAOuF,SAAS,CAACtC,EAAjB,KAAwB,UAJ5B,EAKG;AACCqC,sBAAAA,OAAO,GAAG,MAAI,CAACjC,IAAL,CAAUiC,OAAO,CAACtF,IAAR,CAAauF,SAAb,CAAV,CAAV;AACH,qBAPD,MAOO;AACHD,sBAAAA,OAAO,GAAG,MAAI,CAACjC,IAAL,CAAUiC,OAAV,EAAmBF,GAAnB,CAAuBG,SAAvB,CAAV;AACH;AACJ;AAZJ;AAAA;AAAA;AAAA;AAAA;;AAcG,gBAAA,MAAI,CACClC,IADL,CACUiC,OADV,EAEKtF,IAFL,CAEU8B,GAFV;;AAdH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAD,KAmBKhB,IAnBL,GAoBKgC,KApBL,CAoBW,UAAAC,CAAC,EAAI;AACR,eAAOjB,GAAG,CAACkB,KAAJ,CAAUD,CAAV,CAAP;AACH,OAtBL;;AAwBA,aAAOjB,GAAP;AACH;;;WAuRD,mBAAiB0D,KAAjB,EAAsC;AAAA,UAAdnB,OAAc,uEAAJ,EAAI;AAClC,UAAM/D,GAAG,GAAG,IAAI,IAAJ,CAAS+D,OAAT,CAAZ;AACAmB,MAAAA,KAAK,GAAGA,KAAK,CAACC,KAAN,EAAR;AACAD,MAAAA,KAAK,CAACE,OAAN,CAAc,UAACzB,IAAD;AAAA,eAAU3D,GAAG,CAACqF,KAAJ,CAAU1B,IAAV,CAAV;AAAA,OAAd;AACA3D,MAAAA,GAAG,CAACqC,GAAJ;AACA,aAAOrC,GAAP;AACH;AAED;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACI,sBAAoBoE,QAApB,EAA8BL,OAA9B,EAAuC;AACnC,aAAO,IAAI,IAAJ,CAAS7E,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkB4E,OAAlB,EAA2B;AACvC;AACA;AACA;AACA;AACMuB,QAAAA,YALiC,0BAKlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BACElB,QAAQ,CAAClC,IAAT,EADF;;AAAA;AACXqD,oBAAAA,IADW;;AAAA,yBAEbA,IAAI,CAACC,IAFQ;AAAA;AAAA;AAAA;;AAAA,yBAGND,IAAI,CAACE,KAHC;AAAA;AAAA;AAAA;;AAAA;AAAA,2BAGcF,IAAI,CAACE,KAHnB;;AAAA;AAAA;AAAA,kDAG0B,IAH1B;AAAA;AAAA;;AAAA;AAAA,mCAGkC,CAAC,IAAD,CAHlC;;AAAA;AAAA;;AAAA;AAAA;AAAA,2BAKCF,IAAI,CAACE,KALN;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAOpB;AAZsC,OAA3B,CAAT,CAAP;AAcH;;;;EAv0BoBlH,sB;AA23BzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEAS,UAAU,CAAC0G,SAAX,CAAqBC,cAArB,GAAsC3G,UAAU,CAAC0G,SAAX,CAAqBE,SAA3D;AACA5G,UAAU,CAAC0G,SAAX,CAAqBG,cAArB,GAAsC7G,UAAU,CAAC0G,SAAX,CAAqBI,SAA3D;AAEAC,MAAM,CAACC,OAAP,GAAiBhH,UAAjB","sourcesContent":["const {PromiseTransformStream} = require(\"./util/promise-transform-stream\");\nconst {Readable, Writable, Transform} = require(\"stream\");\nconst scramjet = require(\".\");\n\nconst {\n    AsyncGeneratorFunction,\n    GeneratorFunction,\n    resolveCalleeBlackboxed,\n    pipeIfTarget\n} = require(\"./util/utils\");\n\n/**\n * DataStream is the primary stream type for Scramjet. When you parse your\n * stream, just pipe it you can then perform calculations on the data objects\n * streamed through your flow.\n *\n * Use as:\n *\n * ```javascript\n * const { DataStream } = require('scramjet');\n *\n * await (DataStream.from(aStream) // create a DataStream\n *     .map(findInFiles)           // read some data asynchronously\n *     .map(sendToAPI)             // send the data somewhere\n *     .run());                    // wait until end\n * ```\n * @memberof module:scramjet.\n * @alias DataStream\n * @borrows module:scramjet.DataStream#bufferify as module:scramjet.DataStream#toBufferStream\n * @borrows module:scramjet.DataStream#stringify as module:scramjet.DataStream#toStringStream\n * @extends import(\"stream\").PassThrough\n */\nclass DataStream extends PromiseTransformStream {\n\n    /**\n     * Create the DataStream.\n     *\n     * @param {DataStreamOptions} [opts={}] Stream options passed to superclass\n     *\n     * @test test/methods/data-stream-constructor.js\n     */\n    constructor(opts) {\n        super(Object.assign({\n            objectMode: true,\n            writableObjectMode: true,\n            readableObjectMode: true\n        }, opts));\n    }\n\n    /**\n     * Returns a DataStream from pretty much anything sensibly possible.\n     *\n     * Depending on type:\n     * * `self` will return self immediately\n     * * `Readable` stream will get piped to the current stream with errors forwarded\n     * * `Array` will get iterated and all items will be pushed to the returned stream.\n     *   The stream will also be ended in such case.\n     * * `GeneratorFunction` will get executed to return the iterator which will be used as source for items\n     * * `AsyncGeneratorFunction` will also work as above (including generators) in node v10.\n     * * `Iterable`s iterator will be used as a source for streams\n     *\n     * You can also pass a `Function` or `AsyncFunction` that will be executed and it's outcome will be\n     * passed again to `from` and piped to the initially returned stream. Any additional arguments will be\n     * passed as arguments to the function.\n     *\n     * If a `String` is passed, scramjet will attempt to resolve it as a module and use the outcome\n     * as an argument to `from` as in the Function case described above. For more information see {@link modules.md}\n     *\n     * A simple example from a generator:\n     *\n     * ```javascript\n     * DataStream\n     *   .from(function* () {\n     *      while(x < 100) yield {x: x++};\n     *   })\n     *   .each(console.log)\n     *   // {x: 0}\n     *   // {x: 1}\n     *   // ...\n     *   // {x: 99}\n     * ```\n     *\n     * @param {Array|Iterable<any>|AsyncGeneratorFunction|GeneratorFunction|AsyncFunction|Promise<any>|Function|string|Readable} input argument to be turned into new stream\n     * @param {DataStreamOptions|Writable} [options={}] options for creation of a new stream or the target stream\n     * @param {any[]} ...args additional arguments for the stream - will be passed to the function or generator\n     * @return {DataStream}\n     */\n    static from(input, options, ...args) {\n        const target = options instanceof this && options;\n\n        const {errors: {StreamError}} = scramjet;\n\n        if (input instanceof this) {\n            return target ? input.pipe(target) : input;\n        }\n\n        if (input instanceof Readable || (\n            typeof input.readable === \"boolean\" &&\n            typeof input.pipe === \"function\" &&\n            typeof input.on === \"function\"\n        )) {\n            const out = target || new this(\n                Object.assign(\n                    {},\n                    options,\n                    { referrer: input instanceof DataStream ? input : null }\n                )\n            );\n\n            input.pipe(out);\n            input.on(\"error\", e => out.raise(e));\n            return out;\n        }\n\n        if (input instanceof GeneratorFunction || input instanceof AsyncGeneratorFunction) {\n            const iterator = input(...args);\n            const iteratorStream = this.fromIterator(iterator, options);\n            return pipeIfTarget(iteratorStream, target);\n        }\n\n        if (Array.isArray(input))\n            return pipeIfTarget(this.fromArray(input, options), target);\n\n        const iter = input[Symbol.iterator] || (Symbol.asyncIterator && input[Symbol.asyncIterator]);\n        if (iter) {\n            try {\n                const iterator = iter.call(input);\n                return pipeIfTarget(this.fromIterator(iterator, options), target);\n            } catch(e) {\n                const out = target || new this();\n                out.raise(new StreamError(e, out, \"EXTERNAL\", null));\n\n                return out;\n            }\n        }\n\n        if (input instanceof Promise) {\n            const out = new this(Object.assign({}, options));\n\n            input\n                .then(source => this.from(source, out))\n                .catch(e => out.raise(new StreamError(e, out, \"EXTERNAL\", null)));\n\n            return out;\n        }\n\n        if (typeof input === \"function\") {\n            const out = new this(Object.assign({}, options));\n\n            Promise.resolve(options)\n                .then(input)\n                .then(source => this.from(source, out))\n                .catch(e => out.raise(new StreamError(e, out, \"EXTERNAL\", null)));\n\n            return out;\n        }\n\n        if (typeof input === \"string\") {\n            return new DataStream([]).use(input, ...args);\n        }\n\n        throw new Error(\"Cannot return a stream from passed object\");\n    }\n\n    /**\n     * @callback MapCallback\n     * @memberof module:scramjet~\n     * @param {any} chunk the chunk to be mapped\n     * @returns {Promise<any>|any}  the mapped object\n     */\n\n    /**\n     * Transforms stream objects into new ones, just like Array.prototype.map\n     * does.\n     *\n     * Map takes an argument which is the Function function operating on every element\n     * of the stream. If the function returns a Promise or is an AsyncFunction then the\n     * stream will await for the outcome of the operation before pushing the data forwards.\n     *\n     * A simple example that turns stream of urls into stream of responses\n     *\n     * ```javascript\n     * stream.map(async url => fetch(url));\n     * ```\n     *\n     * Multiple subsequent map operations (as well as filter, do, each and other simple ops)\n     * will be merged together into a single operation to improve performance. Such behaviour\n     * can be suppressed by chaining `.tap()` after `.map()`.\n     *\n     * @param {MapCallback} func The function that creates the new object\n     * @param {function(new:DataStream)} [ClassType=this.constructor] The class to be mapped to.\n     * @chainable\n     *\n     * @test test/methods/data-stream-map.js\n     */\n    map(func, ClassType = this.constructor) {\n        return this.pipe(new ClassType({\n            promiseTransform: func,\n            referrer: this\n        }));\n    }\n\n    /**\n     * @callback FilterCallback\n     * @memberof module:scramjet~\n     * @param {any} chunk the chunk to be filtered or not\n     * @returns {Promise<Boolean>|Boolean} information if the object should remain in the filtered stream.\n     */\n\n    /**\n     * Filters object based on the function outcome, just like Array.prototype.filter.\n     *\n     * Filter takes a Function argument which should be a Function or an AsyncFunction that\n     * will be called on each stream item. If the outcome of the operation is `falsy` (`0`, `''`,\n     * `false`, `null` or `undefined`) the item will be filtered from subsequent operations\n     * and will not be pushed to the output of the stream. Otherwise the item will not be affected.\n     *\n     * A simple example that filters out non-2xx responses from a stream\n     *\n     * ```javascript\n     * stream.filter(({statusCode}) => !(statusCode >= 200 && statusCode < 300));\n     * ```\n     *\n     * @chainable\n     * @param  {FilterCallback} func The function that filters the object\n     *\n     * @test test/methods/data-stream-filter.js\n     */\n    filter(func) {\n        return this.pipe(this._selfInstance({\n            promiseTransform: func,\n            afterTransform: (chunk, ret) => ret ? chunk : Promise.reject(DataStream.filter),\n            referrer: this\n        }));\n    }\n\n    /**\n     * @callback ReduceCallback\n     * @memberof module:scramjet~\n     * @param {any} accumulator the accumulator - the object initially passed or returned by the previous reduce operation\n     * @param {object} chunk the stream chunk.\n     * @return {Promise<any>|any}  accumulator for the next pass\n     */\n\n    /**\n     * Reduces the stream into a given accumulator\n     *\n     * Works similarly to Array.prototype.reduce, so whatever you return in the\n     * former operation will be the first operand to the latter. The result is a\n     * promise that's resolved with the return value of the last transform executed.\n     *\n     * A simple example that sums values from a stream\n     *\n     * ```javascript\n     * stream.reduce((accumulator, {value}) => accumulator + value);\n     * ```\n     *\n     * This method is serial - meaning that any processing on an entry will\n     * occur only after the previous entry is fully processed. This does mean\n     * it's much slower than parallel functions.\n     *\n     * @async\n     * @param {ReduceCallback} func The into object will be passed as the  first argument, the data object from the stream as the second.\n     * @param {object} into Any object passed initially to the transform function\n     *\n     * @test test/methods/data-stream-reduce.js\n     */\n    reduce(func, into) {\n\n        let last = Promise.resolve(into);\n\n        return this.tap()\n            .pipe(new PromiseTransformStream({\n                promiseTransform: (chunk) => {\n                    return last = last.then((acc) => func(acc, chunk));\n                },\n                referrer: this,\n                initial: into\n            }))\n            .resume()\n            .whenFinished()\n            .then(() => last);\n    }\n\n    /**\n     * @callback DoCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {object} chunk source stream chunk\n     * @returns {Promise<any>|any} the outcome is discarded\n     */\n\n    /**\n     * Perform an asynchronous operation without changing or resuming the stream.\n     *\n     * In essence the stream will use the call to keep the backpressure, but the resolving value\n     * has no impact on the streamed data (except for possible mutation of the chunk itself)\n     *\n     * @chainable\n     * @param {DoCallback} func the async function\n     */\n    do(func) {\n        return this.map(async (chunk) => (await func(chunk), chunk));\n    }\n\n    /**\n     * Processes a number of functions in parallel, returns a stream of arrays of results.\n     *\n     * This method is to allow running multiple asynchronous operations and receive all the\n     * results at one, just like Promise.all behaves.\n     *\n     * Keep in mind that if one of your methods rejects, this behaves just like Promise.all\n     * you won't be able to receive partial results.\n     *\n     * @chainable\n     * @param {Function[]} functions list of async functions to run\n     *\n     * @test test/methods/data-stream-all.js\n     */\n    all(functions) {\n        return this.map(chunk => {\n            const chunkPromise = Promise.resolve(chunk);\n            return Promise.all(functions.map(func => chunkPromise.then(func)));\n        });\n    }\n\n    /**\n     * Processes a number of functions in parallel, returns the first resolved.\n     *\n     * This method is to allow running multiple asynchronous operations awaiting just the\n     * result of the quickest to execute, just like Promise.race behaves.\n     *\n     * Keep in mind that if one of your methods it will only raise an error if that was\n     * the first method to reject.\n     *\n     * @chainable\n     * @param {Function[]} functions list of async functions to run\n     *\n     * @test test/methods/data-stream-race.js\n     */\n    race(functions) {\n        return this.map(chunk => {\n            const chunkPromise = Promise.resolve(chunk);\n            return Promise.race(functions.map(func => chunkPromise.then(func)));\n        });\n    }\n\n    /**\n     * Allows processing items without keeping order\n     *\n     * This method useful if you are not concerned about the order in which the\n     * chunks are being pushed out of the operation. The `maxParallel` option is\n     * still used for keeping a number of simultaneous number of parallel operations\n     * that are currently happening.\n     *\n     * @param {MapCallback} func the async function that will be unordered\n     */\n    unorder(func) {\n        const waiting = [];\n        const processing = Array(this._options.maxParallel).fill(null);\n        const out = this._selfInstance({referrer: this});\n\n        this\n            .each(async chunk => {\n                // we're using this race condition on purpose\n                /* eslint-disable require-atomic-updates */\n                let slot = processing.findIndex(x => x === null);\n                if (slot < 0 && processing.length < this._options.maxParallel) slot = processing.length;\n                if (slot < 0) slot = await new Promise(res => waiting.push(res));\n\n                processing[slot] = Promise\n                    .resolve(chunk)\n                    .then(func)\n                    .then(result => out.whenWrote(result))\n                    .then(() => {\n                        const next = waiting.shift();\n                        if (next) next(slot);\n                        else processing[slot] = null;\n                    });\n                /* eslint-enable require-atomic-updates */\n            })\n            .run()\n            .then(() => Promise.all(processing))\n            .then(() => out.end());\n\n        return out;\n    }\n\n    /**\n     * @callback IntoCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {*} into stream passed to the into method\n     * @param {any} chunk source stream chunk\n     * @return {Promise<any>|any} resolution for the old stream (for flow control only)\n     */\n\n    /**\n     * Allows own implementation of stream chaining.\n     *\n     * The async Function is called on every chunk and should implement writes in it's own way. The\n     * resolution will be awaited for flow control. The passed `into` argument is passed as the first\n     * argument to every call.\n     *\n     * It returns the DataStream passed as the second argument.\n     *\n     * @chainable\n     * @param  {IntoCallback} func the method that processes incoming chunks\n     * @param  {DataStream} into the DataStream derived class\n     *\n     * @test test/methods/data-stream-into.js\n     */\n    into(func, into) {\n        if (!(into instanceof DataStream)) throw new Error(\"Stream must be passed!\");\n\n        if (!into._options.referrer)\n            into.setOptions({referrer: this});\n\n        this.tap()\n            .catch(e => into.raise(e))\n            .pipe(new (this.constructor)({\n                promiseTransform: async (chunk) => {\n                    try {\n                        await func(into, chunk);\n                    } catch(e) {\n                        into.raise(e);\n                    }\n                },\n                referrer: this\n            }))\n            .on(\"end\", () => into.end())\n            .resume();\n\n        return into;\n    }\n\n    /**\n     * @callback UseCallback\n     * @memberof module:scramjet~\n     * @async\n     * @param {DataStream} stream\n     * @param  {any[]} ...parameters\n     * @returns {DataStream}\n     */\n\n    /**\n     * Calls the passed method in place with the stream as first argument, returns result.\n     *\n     * The main intention of this method is to run scramjet modules - transforms that allow complex transforms of\n     * streams. These modules can also be run with [scramjet-cli](https://github.com/signicode/scramjet-cli) directly\n     * from the command line.\n     *\n     * @chainable\n     * @param {AsyncGeneratorFunction|GeneratorFunction|UseCallback|string|Readable} func if passed, the function will be called on self to add an option to inspect the stream in place, while not breaking the transform chain. Alternatively this can be a relative path to a scramjet-module. Lastly it can be a Transform stream.\n     * @param {any[]} ...parameters any additional parameters top be passed to the module\n     * @test test/methods/data-stream-use.js\n     */\n    use(func, ...parameters) {\n        if (typeof func == \"string\") {\n            func = require(func.startsWith(\".\") ? resolveCalleeBlackboxed(func) : func);\n        }\n\n        if (func instanceof Transform || (\n            typeof func.readable === \"boolean\" && func.readable &&\n            typeof func.writable === \"boolean\" && func.writable &&\n            typeof func.pipe === \"function\" &&\n            typeof func.on === \"function\"\n        )) {\n            return this.constructor.from(this.pipe(func));\n        }\n\n        if (func instanceof GeneratorFunction || func instanceof AsyncGeneratorFunction) {\n            return this.constructor.from(func, {}, this, ...parameters);\n        }\n\n        if (typeof func === \"function\") {\n            const result = func(this, ...parameters);\n            if (result instanceof Promise) {\n                const out = new this.constructor();\n                result\n                    .then(res => this.constructor.from(res).pipe(out))\n                    .catch(e => out.raise(e));\n\n                return out;\n            } else {\n                return result;\n            }\n        }\n\n        throw new Error(\"Unknown argument type.\");\n    }\n\n    /**\n     * Consumes all stream items doing nothing. Resolves when the stream is ended.\n     *\n     * This is very convienient if you're looking to use up the stream in operations that work on each entry like `map`. This uncorks the stream\n     * and allows all preceding operations to be run at any speed.\n     *\n     * All the data of the current stream will be discarded.\n     *\n     * The function returns a promise that is resolved when the stream ends.\n     *\n     * @async\n     */\n    async run() {\n        return this.tap()\n            .pipe(new DataStream())\n            .on(\"data\", () => 0)\n            .whenEnd();\n    }\n\n    /**\n     * Creates a pipeline of streams and returns a scramjet stream.\n     *\n     * This is similar to node.js stream pipeline method, but also takes scramjet modules\n     * as possibilities in an array of transforms. It may be used to run a series of non-scramjet\n     * transform streams.\n     *\n     * The first argument is anything streamable and will be sanitized by {@link DataStream..from}.\n     *\n     * Each following argument will be understood as a transform and can be any of:\n     * * AsyncFunction or Function - will be executed by {@link DataStream..use}\n     * * A transform stream that will be piped to the preceding stream\n     *\n     * @param {Array|Iterable<any>|AsyncGeneratorFunction|GeneratorFunction|AsyncFunction|Function|string|Readable} readable the initial readable argument that is streamable by scramjet.from\n     * @param {Array<AsyncFunction|Function|Transform>} ...transforms Transform functions (as in {@link DataStream..use}) or Transform streams (any number of these as consecutive arguments)\n     *\n     * @returns {DataStream} a new DataStream instance of the resulting pipeline\n     */\n    static pipeline(readable, ...transforms) {\n        const out = new this();\n        let current = this.from(readable);\n\n        (async () => {\n            for (let transform of transforms) {\n                if (transform instanceof Transform || (\n                    typeof transform.readable === \"boolean\" && transform.readable &&\n                    typeof transform.writable === \"boolean\" && transform.writable &&\n                    typeof transform.pipe === \"function\" &&\n                    typeof transform.on === \"function\"\n                )) {\n                    current = this.from(current.pipe(transform));\n                } else {\n                    current = this.from(current).use(transform);\n                }\n            }\n\n            this\n                .from(current)\n                .pipe(out);\n\n        })()\n            .then()\n            .catch(e => {\n                return out.raise(e);\n            });\n\n        return out;\n    }\n\n    /**\n     * Stops merging transform Functions at the current place in the command chain.\n     *\n     * @name tap\n     * @chainable\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @test test/methods/data-stream-tap.js\n     */\n\n    /**\n     * Reads a chunk from the stream and resolves the promise when read.\n     *\n     * @async\n     * @name whenRead\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Writes a chunk to the stream and returns a Promise resolved when more chunks can be written.\n     *\n     * @async\n     * @name whenWrote\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {*} chunk a chunk to write\n     * @param {any[]} ...more more chunks to write\n     */\n\n    /**\n     * Resolves when stream ends - rejects on uncaught error\n     *\n     * @async\n     * @name whenEnd\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Returns a promise that resolves when the stream is drained\n     *\n     * @async\n     * @name whenDrained\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Returns a promise that resolves (!) when the stream is errors\n     *\n     * @async\n     * @name whenError\n     * @memberof module:scramjet.DataStream#\n     * @method\n     */\n\n    /**\n     * Allows resetting stream options.\n     *\n     * It's much easier to use this in chain than constructing new stream:\n     *\n     * ```javascript\n     *     stream.map(myMapper).filter(myFilter).setOptions({maxParallel: 2})\n     * ```\n     *\n     * @meta.conditions keep-order,chain\n     *\n     * @memberof module:scramjet.DataStream#\n     * @name setOptions\n     * @method\n     * @param {DataStreamOptions} options\n     * @chainable\n     */\n\n    /**\n     * Returns a copy of the stream\n     *\n     * Creates a new stream and pushes all the data from the current one to the new one.\n     * This can be called serveral times.\n     *\n     * @chainable\n     * @param {TeeCallback|Writable} func The duplicate stream will be passed as first argument.\n     */\n    copy() {\n        return this.tap().pipe(this._selfInstance());\n    }\n\n    /**\n     * Duplicate the stream\n     *\n     * Creates a duplicate stream instance and passes it to the Function.\n     *\n     * @chainable\n     * @param {TeeCallback|Writable} func The duplicate stream will be passed as first argument.\n     *\n     * @test test/methods/data-stream-tee.js\n     */\n    tee(func) {\n        if (func instanceof Writable)\n            return (this.tap().pipe(func), this);\n        func(this.pipe(this._selfInstance()));\n        return this.tap();\n    }\n\n    /**\n     * @callback TeeCallback\n     * @memberof module:scramjet~\n     * @param {DataStream} teed The teed stream\n     */\n\n    /**\n     * Performs an operation on every chunk, without changing the stream\n     *\n     * This is a shorthand for ```stream.on(\"data\", func)``` but with flow control.\n     * Warning: this resumes the stream!\n     *\n     * @chainable\n     * @param  {MapCallback} func a Function called for each chunk.\n     */\n    each(func) {\n        return this.tap().map(\n            (a) => Promise.resolve(func(a))\n                .then(() => a)\n        ).resume();\n    }\n\n    /**\n     * Reads the stream while the function outcome is truthy.\n     *\n     * Stops reading and emits end as soon as it finds the first chunk that evaluates\n     * to false. If you're processing a file until a certain point or you just need to\n     * confirm existence of some data, you can use it to end the stream before reaching end.\n     *\n     * Keep in mind that whatever you piped to the stream will still need to be handled.\n     *\n     * @chainable\n     * @param  {FilterCallback} func The condition check\n     *\n     * @test test/methods/data-stream-while.js\n     */\n    while(func) {\n        let condition = true;\n        const out = this._selfInstance();\n        return this.tap().pipe(out.filter(\n            (chunk) => {\n                const result = condition && func(chunk);\n                if (condition != result) {\n                    condition = result;\n                    this.unpipe(out);\n                    out.end();\n                }\n\n                return Promise\n                    .resolve(result)\n                    .then(result => result ? chunk : Promise.reject(DataStream.filter));\n            }\n        ));\n    }\n\n    /**\n     * Reads the stream until the function outcome is truthy.\n     *\n     * Works opposite of while.\n     *\n     * @chainable\n     * @param  {FilterCallback} func The condition check\n     *\n     * @test test/methods/data-stream-until.js\n     */\n    until(func) {\n        let condition = false;\n        const out = this._selfInstance();\n        return this.tap().pipe(out).filter(\n            (chunk) => {\n                const result = condition || func(chunk);\n                const ref = !result ? chunk : Promise.reject(DataStream.filter);\n\n                if (condition != result) {\n                    condition = result;\n                    this.unpipe(out);\n                    out.end();\n                }\n\n                return ref;\n            }\n        );\n    }\n\n    /**\n     * Provides a way to catch errors in chained streams.\n     *\n     * The handler will be called as asynchronous\n     *  - if it resolves then the error will be muted.\n     *  - if it rejects then the error will be passed to the next handler\n     *\n     * If no handlers will resolve the error, an `error` event will be emitted\n     *\n     * @chainable\n     * @name catch\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {Function} callback Error handler (async function)\n     *\n     * @test test/methods/data-stream-catch.js\n     */\n\n    /**\n     * Executes all error handlers and if none resolves, then emits an error.\n     *\n     * The returned promise will always be resolved even if there are no successful handlers.\n     *\n     * @async\n     * @name raise\n     * @memberof module:scramjet.DataStream#\n     * @method\n     * @param {Error} err The thrown error\n     *\n     * @test test/methods/data-stream-raise.js\n     */\n\n    /**\n     * Override of node.js Readable pipe.\n     *\n     * Except for calling overridden method it proxies errors to piped stream.\n     *\n     * @name pipe\n     * @chainable\n     * @ignore\n     * @method\n     * @memberof module:scramjet.DataStream#\n     * @param  {NodeJS.WritableStream} to  Writable stream to write to\n     * @param  {WritableOptions} [options={}]\n     * @return {NodeJS.WritableStream}  the `to` stream\n     */\n\n    /**\n     * Creates a BufferStream.\n     *\n     * The passed serializer must return a buffer.\n     *\n     * @meta.noReadme\n     * @chainable\n     * @param  {MapCallback} serializer A method that converts chunks to buffers\n     * @return {BufferStream}  the resulting stream\n     *\n     * @test test/methods/data-stream-tobufferstream.js\n     */\n    bufferify(serializer) {\n        return this.map(serializer, scramjet.BufferStream);\n    }\n\n    /**\n     * Creates a StringStream.\n     *\n     * The passed serializer must return a string. If no serializer is passed chunks\n     * toString method will be used.\n     *\n     * @chainable\n     * @param  {MapCallback|never} [serializer] A method that converts chunks to strings\n     * @return {StringStream} the resulting stream\n     *\n     * @test test/methods/data-stream-tostringstream.js\n     */\n    stringify(serializer = a => `${a}`) {\n        return this.map(serializer, scramjet.StringStream);\n    }\n\n    /**\n     * Create a DataStream from an Array\n     *\n     * @param  {Array<*>} array list of chunks\n     * @param {DataStreamOptions} [options={}] the read stream options\n     * @return {DataStream}\n     *\n     * @test test/methods/data-stream-fromarray.js\n     */\n    static fromArray(array, options = {}) {\n        const ret = new this(options);\n        array = array.slice();\n        array.forEach((item) => ret.write(item));\n        ret.end();\n        return ret;\n    }\n\n    /**\n     * Create a DataStream from an Iterator\n     *\n     * Doesn't end the stream until it reaches end of the iterator.\n     *\n     * @param {Iterator<any>} iterator the iterator object\n     * @param {DataStreamOptions} [options={}] the read stream options\n     * @return {DataStream}\n     *\n     * @test test/methods/data-stream-fromiterator.js\n     */\n    static fromIterator(iterator, options) {\n        return new this(Object.assign({}, options, {\n            // TODO: handle count argument\n            // problem here is how do we know which promises are resolved and until where?\n            // need to queue a number of promises up to maxParallel, but push them with\n            // Promise.all with the previous one.\n            async parallelRead() {\n                const read = await iterator.next();\n                if (read.done) {\n                    return read.value ? [await read.value, null] : [null];\n                } else {\n                    return [await read.value];\n                }\n            }\n        }));\n    }\n\n    /**\n     * Aggregates the stream into a single Array\n     *\n     * In fact it's just a shorthand for reducing the stream into an Array.\n     *\n     * @async\n     * @param  {Array} [initial=[]] Array to begin with (defaults to an empty array).\n     * @returns {any[]}\n     */\n    toArray(initial = []) {\n        return this.reduce(\n            (arr, item) => (arr.push(item), arr),\n            initial\n        );\n    }\n\n    /**\n     * Returns an async generator\n     *\n     * @return {Generator<Promise<any>>} Returns an iterator that returns a promise for each item.\n     */\n    toGenerator() {\n        this.tap();\n        const ref = this;\n        return function* () {\n            let ended = false;\n            ref.on(\"end\", () => ended = true);\n            while (!ended) {\n                yield ref.whenRead();\n            }\n            return;\n        };\n    }\n\n    /**\n     * Returns a new instance of self.\n     *\n     * Normally this doesn't have to be overridden.\n     * When the constructor would use some special arguments this may be used to\n     * override the object construction in {@link tee}...\n     *\n     * @meta.noReadme\n     * @memberof module:scramjet.DataStream#\n     * @name _selfInstance\n     * @method\n     * @return {DataStream}  an empty instance of the same class.\n     * @test test/methods/data-stream-selfinstance.js\n     */\n}\n\n/**\n * Transform async callback. The passed transform should return a new chunk, unless\n * the output should be filtered - if so, the transform should return `undefined`.\n *\n * Additionally the function can reject with `DataStream.filter` - the result will be\n * filtered and no other transforms will be run on the chunk.\n *\n * @callback ScramjetTransformCallback\n * @memberof module:scramjet~\n * @param {Buffer|string|any} chunk the stream chunk\n * @param {string} encoding encoding of the chunk\n * @returns {Promise<any|undefined>|any|undefined} the result, undefined will be treated as filtered out.\n */\n\n/**\n * Write async callback. Await your async write and resolve.\n *\n * @callback ScramjetWriteCallback\n * @memberof module:scramjet~\n * @param {Buffer|string|any} chunk the stream chunk\n * @param {string} encoding encoding of the chunk\n * @returns {Promise<void>|void} should resolve when the write ends\n */\n\n/**\n * Read async callback. Simply await your async operations and return the result as array.\n *\n * @callback ScramjetReadCallback\n * @memberof module:scramjet~\n * @param {number} count the number of chunks that should be read (\"this is more like a set of guideline than actual rules\").\n * @returns {Array<any>|Promise<Array<any>>} the read chunk.\n */\n\n/**\n * Standard options for scramjet streams.\n *\n * Defines async transforms or read/write methods for a stream.\n * @typedef {object} DataStreamOptions\n * @memberof module:scramjet~\n * @property {ScramjetReadCallback} [promiseRead=null] an async function returning the next read item\n * @property {ScramjetWriteCallback} [promiseWrite=null] an async function writing the next written item\n * @property {ScramjetTransformCallback} [promiseTransform=null] an async function returning a transformed chunk\n * @property {ScramjetReadCallback} [promiseFlush=null] an async function run before transform stream ends to push last chunks from the buffer\n * @property {ScramjetTransformCallback} [beforeTransform=null] an async function run before the transform\n * @property {ScramjetTransformCallback} [afterTransform=null] an async function run after the transform\n * @property {number} [maxParallel=os.cpus.length*2] the number of transforms done in parallel\n * @property {DataStream} [referrer=null] a referring stream to point to (if possible the transforms will be pushed to it\n * @property {boolean} [objectMode=true] should the object mode be used instead of creating a new stream)\n * @property {number} [highWaterMark] The maximum number of bytes to store in the internal buffer before ceasing to read from the underlying resource. Default: 16384 (16KB), or 16 for objectMode streams.\n * @property {string} [encoding] If specified, then buffers will be decoded to strings using the specified encoding. Default: null.\n * @property {boolean} [emitClose] Whether or not the stream should emit 'close' after it has been destroyed. Default: true.\n * @property {Function} [read] Implementation for the stream._read() method.\n * @property {Function} [destroy] Implementation for the stream._destroy() method.\n * @property {Function} [construct] Implementation for the stream._construct() method.\n * @property {boolean} [autoDestroy] Whether this stream should automatically call .destroy() on itself after ending. Default: true.\n */\n\nDataStream.prototype.toBufferStream = DataStream.prototype.bufferify;\nDataStream.prototype.toStringStream = DataStream.prototype.stringify;\n\nmodule.exports = DataStream;\n"]},"metadata":{},"sourceType":"script"}